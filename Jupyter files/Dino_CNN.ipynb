{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a88a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# for warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "imgs = glob.glob(\"./img/*.png\")\n",
    "\n",
    "# img size\n",
    "width = 250\n",
    "height = 100\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for img in imgs:\n",
    "    \n",
    "    fileName = os.path.basename(img)\n",
    "    label = fileName.split('_')[0] \n",
    "    \n",
    "    # \"L\" for grayscale. normalized with 255\n",
    "    im = np.array(Image.open(img).convert(\"L\").resize((width, height))) / 255\n",
    "    X.append(im)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], width, height, 1)  # 1 is channel\n",
    "\n",
    "def onehotLabels(values):\n",
    "    labelEncoder = LabelEncoder()\n",
    "    integerEncoded = labelEncoder.fit_transform(values)\n",
    "    onehotEncoder = OneHotEncoder(sparse=False)\n",
    "    integerEncoded = integerEncoded.reshape(len(integerEncoded), 1)\n",
    "    onehot_encoded = onehotEncoder.fit_transform(integerEncoded)\n",
    "    return onehot_encoded\n",
    "\n",
    "Y = onehotLabels(Y)\n",
    "\n",
    "#train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25, random_state = 2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294182fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0506 - accuracy: 0.5000\n",
      "Epoch 2/35\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 36.6785 - accuracy: 0.4444\n",
      "Epoch 3/35\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 44.9265 - accuracy: 0.2778\n",
      "Epoch 4/35\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 13.5835 - accuracy: 0.2778\n",
      "Epoch 5/35\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 9.9648 - accuracy: 0.2222\n",
      "Epoch 6/35\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 8.0806 - accuracy: 0.3333\n",
      "Epoch 7/35\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 7.0087 - accuracy: 0.3889\n",
      "Epoch 8/35\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 4.4298 - accuracy: 0.5000\n",
      "Epoch 9/35\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 2.6141 - accuracy: 0.4444\n",
      "Epoch 10/35\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 1.4694 - accuracy: 0.4444\n",
      "Epoch 11/35\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 1.2314 - accuracy: 0.4444\n",
      "Epoch 12/35\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1.0231 - accuracy: 0.6111\n",
      "Epoch 13/35\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 0.9782 - accuracy: 0.6111\n",
      "Epoch 14/35\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 1.0233 - accuracy: 0.4444\n",
      "Epoch 15/35\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.8085 - accuracy: 0.5000\n",
      "Epoch 16/35\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.6609 - accuracy: 0.8333\n",
      "Epoch 17/35\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.5414 - accuracy: 0.8889\n",
      "Epoch 18/35\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.5967 - accuracy: 0.6111\n",
      "Epoch 19/35\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.3782 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.3242 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.2494 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 0.3637 - accuracy: 0.8889\n",
      "Epoch 23/35\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.2323 - accuracy: 0.9444\n",
      "Epoch 24/35\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.1214 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.1118 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.1023 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 0.0769 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.0868 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.0060 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6bde9cd00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3, activation=\"softmax\"))      \n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics= [\"accuracy\"])  \n",
    "\n",
    "model.fit(trainX, trainY, epochs=35, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaba53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c59153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# # Assuming trainY contains class labels as integers (e.g., [0, 1, 2, ...])\n",
    "# # Convert the class labels to one-hot encoded format\n",
    "# trainY_onehot = to_categorical(trainY, num_classes=3)\n",
    "# testY_onehot = to_categorical(testY, num_classes=3)\n",
    "\n",
    "# # Now, train the model with the one-hot encoded target labels\n",
    "# model.fit(trainX, trainY_onehot, epochs=35, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65f558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Training Accuracy: % 100.0\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2117 - accuracy: 0.8571\n",
      "Test Accuracy: % 85.71428656578064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Trained Weights\n",
    "if os.path.exists(\"./trex_weight.h5\"):\n",
    "    model.load_weights(\"trex_weight.h5\")\n",
    "    print(\"Weights loaded.\") \n",
    "# ############\n",
    "\n",
    "# score_train = model.evaluate(trainX, trainY_onehot)\n",
    "score_train = model.evaluate(trainX, trainY)\n",
    "print(\"Training Accuracy: %\",score_train[1]*100)    \n",
    "    \n",
    "score_test = model.evaluate(testX, testY)\n",
    "print(\"Test Accuracy: %\",score_test[1]*100)  \n",
    "\n",
    "\n",
    "open(\"model_new.json\",\"w\").write(model.to_json())\n",
    "model.save_weights(\"trex_weight_new.h5\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd951b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 248, 98, 32)       320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 246, 96, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 123, 48, 64)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 123, 48, 64)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 377856)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               48365696  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,384,899\n",
      "Trainable params: 48,384,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cf947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
